diff --git a/linux/notes/bogomips/Measurements b/linux/notes/bogomips/Measurements
index 9881506..d9af92f 100644
--- a/linux/notes/bogomips/Measurements
+++ b/linux/notes/bogomips/Measurements
@@ -96,3 +96,36 @@ Perfect !!! Resolution of 1 uSec
 >>>>2388;
 >>>>
 
+
+NOTE
+~~~~~~~
+The calibration is good and proven to work. the part that is needed is to find out if 
+we have OR not the cpu from those data.
+The current way of plotting tell us that sometime it may take a very long time 
+to compute the task. In a graph its not good.
+
+note that IRQ latency is good but it doesn't catch everything since in order to trigger it
+you need to arm it and to arm it you need to run it...
+
+
+
+Another thing would be to have a vector mode ( to compress the data )
+
+
+Another way would be to print the time we are not running ONLY
+
+while(1){
+	t1 = get time
+	delay
+	t2 = get time
+	if(t2 -t1 > Cal)
+		t1 : t2-t1         <<<< Telling that at t1 time We didn't ran for t2 -t1 cycle
+
+So the graph is
+
+TSC start|---------|TSC T1__________________|T1 + T2 - t1|--------------
+
+
+}
+
+--> if( period  
diff --git a/linux/notes/bogomips/bogomips.c b/linux/notes/bogomips/bogomips.c
index b8b839d..5d44c19 100644
--- a/linux/notes/bogomips/bogomips.c
+++ b/linux/notes/bogomips/bogomips.c
@@ -52,7 +52,7 @@
 #define MIN(a,b) (((a)<(b))?(a):(b)) 
 #define MAX(a,b) (((a)>(b))?(a):(b))
 
-#define MAX_LOOPS_NR 1024*1024
+#define MAX_LOOPS_NR 1024
 #define MAX_CPU_NR 64
 
 static int l=0;
@@ -111,7 +111,7 @@ static struct dentry *debugfs_file;
 #define MIN(a,b) (((a)<(b))?(a):(b)) 
 #define MAX(a,b) (((a)>(b))?(a):(b))
 
-#define MAX_LOOPS_NR 1024*1024
+#define MAX_LOOPS_NR 1024
 #define MAX_CPU_NR 64
 
 typedef unsigned long long cycles_t;
@@ -166,6 +166,7 @@ static inline cycles_t get_cycles(void)
 struct per_cpu{
 	char cpu_name[32];
 	uint64_t delta[MAX_LOOPS_NR];
+	int vector_nr[MAX_LOOPS_NR];
 };
 
 static struct per_cpu cpu_dat[MAX_CPU_NR];
@@ -211,8 +212,8 @@ static int measure_tsc_cycle_per_loop(void *arg)
 static void * measure_tsc_cycle_per_loop(void *arg)
 #endif
 {
-	int x,cpu;
-	u64 t1, t2,t3;
+	int x,y,cpu;
+	u64 t1,t2,t3,t4;
 	struct per_cpu *pcpu;
 	unsigned long lpj = j;
 	int loop_nr = l;
@@ -251,7 +252,82 @@ static void * measure_tsc_cycle_per_loop(void *arg)
 			t3 = t1 - t2;
 		__ldelay(lpj);
 		t2 = get_cycles();
-		pcpu->delta[x] = t2-t1 + t3;
+//		t4 = (t2-t1 + t3) & 0xffffffffffffff00;
+		t4 = (t2-t1 + t3) ;
+		if(!x){
+			y=0;
+			pcpu->delta[y] = t4;
+			pcpu->vector_nr[y] = 1;
+		}
+		else if(pcpu->delta[y] == t4 ){
+			pcpu->vector_nr[y]++;
+		}
+		else{
+
+			y++;
+			pcpu->delta[y] = t4;
+			pcpu->vector_nr[y] = 1;
+			/* 
+			 * Because we have a jitter between the various path we
+			 * try to make it even with nop
+			 */
+			asm volatile(
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+				"nop\n"
+			);
+		}
 	}
 #ifdef __KERNEL__
 	local_irq_enable();
@@ -381,11 +457,13 @@ static int tsc_show(struct seq_file *m, void *p)
 			pcpu = &cpu_dat[y];
 			if(!strlen(pcpu->cpu_name))
 				continue;
-			seq_printf(m, "%Lu;",pcpu->delta[x]);
+			if(!pcpu->delta[x])
+				continue;
+			seq_printf(m, "%Lu;%d",pcpu->delta[x],pcpu->vector_nr[x]);
 		}
-		seq_printf(m, "\n",pcpu->cpu_name);
+		seq_printf(m, "\n");
 	}
-	seq_printf(m, "\n",pcpu->cpu_name);
+	seq_printf(m, "\n");
 
 	return 0;
 }
