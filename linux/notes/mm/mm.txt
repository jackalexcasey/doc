On NUMA systems, the global mem map is treated as a virtual array starting at
PAGE OFFSET. The type mem map t is a typedef for struct page, so it can be easily referred
to within the mem map array.

Every physical page frame in the system has an associated struct page that is
used to keep track of its status.

There is a requirement for Linux to have a fast method of mapping virtual addresses
to physical addresses and for mapping struct pages to their physical address.
Linux achieves this by knowing where, in both virtual and physical memory, the
global mem map array is because the global array has pointers to all struct pages
representing physical memory in the system

Physical addresses are translated to struct pages by treating them as an index
into the mem map array. Shifting physical address PAGE SHIFT bits to the right will
treat them as a Page Frame Number (PFN) from physical address 0, which is also
an index within the mem map array. This is exactly what the macro virt to page()


Cache control
~~~~~~~~~~~~~~
Just as some architectures do not automatically manage their TLBs, some do
not automatically manage their CPU caches. The hooks are placed in locations
where the virtual to physical mapping changes, such as during a page table update.
The CPU cache flushes should always take place first because some CPUs require a
virtual to physical mapping to exist when the virtual address is being flushed from
the cache.
	void flush cache all(void)
	This flushes the entire CPU cache system, which makes it the most severe
	flush operation to use. It is used when changes to the kernel page tables, which
	are global in nature, are to be performed.


Page Table Management
~~~~~~~~~~~~~~~~~~~~~
On the x86, the process page table is loaded by copying mm struct→pgd into
the cr3 register, which has the side effect of flushing the TLB. 
In fact, this is how the function flush tlb() is implemented in the
architecture-dependent code.

PTE
	PRESENT
	PROTNONE
	RW
	USER
	DIRTY
	ACCESSED

Page tables, as stated, are physical pages containing an array of entries, and the allocation
and freeing of physical pages is a relatively expensive operation, Hence the pages used 
for the page tables are cached in a number of different lists called quicklists.
The allocation functions are pgd alloc(), pmd alloc() and pte alloc()


Recap
~~~~~~~
struct pages represent physical memory; 1 struct pages  - 1 memory address

PTE define VMA; PTE can overlap i.e. Multiple PTE can point to 1 memory address

Rmap grants the ability to locate all PTEs that map a particular page given just the struct page.

The reverse mapping required for each page can have very expensive space requirements.
To compound the problem, many of the reverse mapped pages in a VMA will be 
essentially identical. One way of addressing this is to reverse map based on the VMAs rather than individual pages.



FORK()
~~~~~~~
Creates a new process with a new address space. All the pages
are marked Copy-On-Write (COW) and are shared between the
two processes until a page fault occurs. Once a write-fault oc-
curs, a copy is made of the COW page for the faulting process.
This is sometimes referred to as breaking a COW page.


CLOSE()
~~~~~~~~
clone() allows a new process to be created that shares parts of
its context with its parent and is how threading is implemented
in Linux. clone() without the CLONE VM set will create a new
address space, which is essentially the same as fork().

Page Frame reclaim
~~~~~~~~~~~~~~~~~~
page cache. All data that is read from disk is stored in the page cache to 
reduce the amount of disk I/O that must be performed

With the exception of the slab allocator, all pages in use by the system are stored on LRU lists and linked
together by page→lru so that they can be easily scanned for replacement. The
slab pages are not stored on the LRU lists because it is considerably more difficult
to age a page based on the objects used by the slab.


how process-mapped pagesare removed. 
Process-mapped pages are not easily swappable because there is no
way to map struct pages to PTEs except to search every page table, which is far
too expensive. If the page cache has a large number of process-mapped pages in it,
process page tables will be walked, and pages will be swapped out by swap out()
until enough pages have been freed, but swap out() will still have trouble with
shared pages. If a page is shared, a swap entry is allocated, the PTE filled with
the necessary information to find the page in swap again and the reference count is
decremented. Only when the count reaches zero will the page be freed. Pages like
this are considered to be in the swap cache.

The objective is for the active list to
contain the working set [Den70] of all processes and the inactive list to contain
reclaim candidates.

The page cache is a set of data structures that contain pages that are backed by
regular files, block devices or swap
The principal reason for the existence of this cache is to eliminate unnecessary
disk reads.


RECLAIM:
The function shrink cache() is the part of the replacement algorithm that takes
pages from the inactive list and decides how they should be swapped out.

LRU, broadly speaking, store the hot and cold pages respectively, or, 
in other words, the active list contains all the working sets in the system, 
and inactive list contains reclaim candidates.

The two starting parameters that determine how much work will be performed are
nr pages and priority. nr pages starts out as SWAP CLUSTER MAX, currently de-
fined as 32 in mm/vmscan.c. The variable priority starts as DEF PRIORITY, cur-
rently defined as 6 in mm/vmscan.c.

Available memory;
~~~~~~~~~~~~~~~~~~
To determine how many pages are potentially available, Linux sums up
the following bits of data:

Total page cache because page cache is easily reclaimed.
Total free pages because they are already available.
Total pages used by the dentry cache because they are easily reclaimed.
Total pages used by the inode cache because they are easily reclaimed.

If the total number of pages added here is sufficient for the request,
vm enough memory() returns true to the caller. If false is returned, the caller knows
that the memory is not available and usually decides to return -ENOMEM to userspace.

Before it reach that point:
When the machine is low on memory, old page frames will be reclaimed

Unfortunately, it is possible that the system is not out of memory and simply
needs to wait for I/O to complete or for pages to be swapped to backing storage.
This is unfortunate, not because the system has memory, but because the function is
being called unnecessarily, which opens the possibly of processes being unnecessarily
killed. Before deciding to kill a process, it goes through the following checklist


**** RECAP ****
~~~~~~~~~~~~~~~
All memory is describe by a struct pages;
LRU active list working set of pages
LRU inactive list contain reclaim candidate
LRU lists and page cache are closely related

The LRU active list size is maintain to about 2/3 LRU inactive list
refill inactive() move pages from the bottom of active list to inactive list
Pages are reclaimed from the inactive list

The function shrink cache() is the part of the replacement algorithm that takes
pages from the inactive list and decides how they should be swapped out.

	Two parameters, max scan and max mapped, determine how much work the
	function will do and are affected by the priority.

	Each time the function shrink caches() is called without enough pages being freed, the priority will be
	decreased until the highest priority 1 is reached.

	This means that, at lowest priority 6, at most one-sixth of the pages in the inactive list
	will be scanned, and, at highest priority, all of them will be

	-Page is mapped by a process. max mapped-- if(max mapped ==0 )page tables of processes will be linearly search at the end
	-The page is locked for I/O
	-Page is dirty, is unmapped by all processes, has no buffers and belongs
	to a device or file mapping.
	-Page has buffers associated with data on disk
	-Page is anonymous and is mapped by more than one process. max mapped-- if(max mapped ==0 ) ...
	-Page has no process referencing it.


	***Swapping Out Process Pages
		linearly searching all processes for the PTEs that reference a particular struct page.
	
The page cache is a set of data structures that contain pages that are backed by
regular files, block devices or swap. Reason is to eliminate disk access:
Pages read from a file or block device are generally added to the page cache to avoid
further disk I/O

 - pages that were faulted in as a result of reading a memory mapped file
 - Blocks read from a block device or filesystem are packed into special pages
   called buffer pages.
 - Anonymous pages exist in a special aspect of the page cache called the swap
   cache
 - Pages belonging to shared memory regions are treated in a similar fashion to
   anonymous pages




Active:          1065676 kB
Inactive:         671944 kB
Active(anon):     445992 kB
Inactive(anon):     7648 kB
Active(file):     619684 kB
Inactive(file):   664296 kB

When pages reach the bottom of the list, the referenced flag is checked.
If it is set, it is moved back to the top of the list, and the next page is checked. If
it is cleared, it is moved to the inactive list.

***
As a final nail in the stack algorithm coffin, the lists
are almost ignored when paging out from processes because pageout decisions are
related to their location in the virtual address space of the process rather than the
location within the page lists.


Scale BAD example:

The first is if the candidates for reclamation are principally anonymous pages. In this case, Linux will keep examining
a large number of pages before linearly scanning process page tables searching for
pages to reclaim, but this situation is fortunately rare.

The second situation is where there is a single process with many file-backed
resident pages in the inactive list that are being written to frequently. Processes
and kswapd may go into a loop of constantly laundering these pages and placing
them at the top of the inactive list without freeing anything. In this case, few
pages are moved from the active list to inactive list because the ratio between
the two lists, sizes remains do not change significantly.



=>>> Memory map file backed up by disk; fd = open("file"; ptr = mmap(...,...,...,fd) ptr[x]=x;)
1) mmap setup the VMA; Backing storage can be memory ( anonymous pages ) OR Disk ( file /fd )
	__do_page_fault
	handle_mm_fault
	handle_pte_fault

2) Anonymous pages// Access the VMA cause a page_fault;
	VMA anonymous do_anonymous_page // Get the memory // setup the PTE

3) Disk backed /// Access the VM cause a page_fault // Try to bring that page in the page cache
	VMA backed up by disk ; if (likely(vma->vm_ops->fault)); return do_linear_fault
		__do_fault
		ret = vma->vm_ops->fault(vma, &vmf); filemap_fault


If we have a program Similar to chewmem that chewpage_cache i.e. file backed mmap && touch all pages
	>> The amount of pages touched represent the memory taken
	>> At some point kswapd will run because of low mem; Try to evict page cache BUT they are constantly touched by the scrubber so
	>> no real work is DONE...
	>>


