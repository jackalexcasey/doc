diff --git a/fs/binfmt_elf.c b/fs/binfmt_elf.c
index e3c6533..e4945b6 100644
--- a/fs/binfmt_elf.c
+++ b/fs/binfmt_elf.c
@@ -1886,6 +1886,50 @@ static size_t elf_core_vma_data_size(struct vm_area_struct *gate_vma,
 	return size;
 }
 
+#define CANARY_PAGES_NR 10
+struct canary_pages{
+	unsigned long pages[CANARY_PAGES_NR];
+};
+
+static void canary_release(struct canary_pages *canary)
+{
+	int x;
+
+	if(!canary)
+		return;
+	for(x=0;x<CANARY_PAGES_NR;x++){
+		if(canary->pages[x]){
+			free_page(canary->pages[x]);
+			canary->pages[x]=0;
+		}
+	}
+	kfree(canary);
+	return;
+}
+
+/*
+ * During a storm of pipe coredump we are subject to OOM deadlock.
+ * For protection, we pump-in a few pages per process before hand so that we
+ * can quickly released them whenever a OOM fatal signal is received.
+ */
+static struct canary_pages* canary_inflate(void)
+{
+	int x;
+	struct canary_pages *canary;
+
+	canary = kzalloc(GFP_KERNEL, sizeof(struct canary_pages));
+	if(!canary)
+		return NULL;
+	for(x=0;x<CANARY_PAGES_NR;x++){
+		canary->pages[x] = __get_free_page(GFP_KERNEL);
+		if(!canary->pages[x]){
+			canary_release(canary);
+			return NULL;
+		}
+	}
+	return canary;
+}
+
 /*
  * Actual dumper
  *
@@ -1906,6 +1950,7 @@ static int elf_core_dump(struct coredump_params *cprm)
 	struct elf_note_info info;
 	struct elf_phdr *phdr4note = NULL;
 	struct elf_shdr *shdr4extnum = NULL;
+	struct canary_pages* canary = NULL;
 	Elf_Half e_phnum;
 	elf_addr_t e_shoff;
 
@@ -1957,6 +2002,10 @@ static int elf_core_dump(struct coredump_params *cprm)
 	fs = get_fs();
 	set_fs(KERNEL_DS);
 
+	canary = canary_inflate();
+	if(!canary)
+		goto end_coredump;
+
 	offset += sizeof(*elf);				/* Elf header */
 	offset += segs * sizeof(struct elf_phdr);	/* Program headers */
 	foffset = offset;
@@ -2066,6 +2115,11 @@ static int elf_core_dump(struct coredump_params *cprm)
 				page_cache_release(page);
 			} else
 				stop = !dump_seek(cprm->file, PAGE_SIZE);
+			/* Monitor fatal signal in the case where current OOM. */
+			if (fatal_signal_pending(current)){
+				printk("\n%s/%d CORE aborted\n", current->comm, task_pid_nr(current));
+				stop = 1;
+			}
 			if (stop)
 				goto end_coredump;
 		}
@@ -2086,6 +2140,7 @@ end_coredump:
 	set_fs(fs);
 
 cleanup:
+	canary_release(canary);
 	free_note_info(&info);
 	kfree(shdr4extnum);
 	kfree(phdr4note);
diff --git a/mm/oom_kill.c b/mm/oom_kill.c
index 7ee7e0d..709aa26 100644
--- a/mm/oom_kill.c
+++ b/mm/oom_kill.c
@@ -228,9 +228,10 @@ static inline enum oom_constraint constrained_alloc(struct zonelist *zonelist,
 static struct task_struct *select_bad_process(unsigned long *ppoints,
 						struct mem_cgroup *mem)
 {
-	struct task_struct *p;
+	struct task_struct *p,*t;
 	struct task_struct *chosen = NULL;
 	struct timespec uptime;
+	int core=0;
 	*ppoints = 0;
 
 	do_posix_clock_monotonic_gettime(&uptime);
@@ -254,10 +255,28 @@ static struct task_struct *select_bad_process(unsigned long *ppoints,
 		 * being killed. Don't allow any other task access to the
 		 * memory reserve.
 		 *
-		 * Note: this may have a chance of deadlock if it gets
-		 * blocked waiting for another task which itself is waiting
-		 * for memory. Is there a better alternative?
+		 * In order to avoid deadlock we need to detect if the task
+		 * which has access to memory reserves is block waiting for 
+		 * another task which itself is waiting for memory. This is
+		 * tricky. 
+		 *
+		 * Pipe coredump is an easy case; Just terminate every process 
+		 * that are core-dumping. Core files are not worth the risk of taking
+		 * an OOM on a legitimate process anyway.
+		 *
+		 * Hopefully, canary will gives us some fresh air.
 		 */
+		if(!core){
+			for_each_process(t) {
+				if (t->flags & PF_DUMPCORE){
+					t->rt.time_slice = HZ;
+					set_tsk_thread_flag(t, TIF_MEMDIE);
+					force_sig(SIGKILL, t);
+				}
+			}
+			core=1;
+		}
+
 		if (test_tsk_thread_flag(p, TIF_MEMDIE))
 			return ERR_PTR(-1UL);
 
@@ -288,7 +307,7 @@ static struct task_struct *select_bad_process(unsigned long *ppoints,
 			*ppoints = points;
 		}
 	}
-
+	printk("\n%s/%d OOM chosen\n", chosen->comm, task_pid_nr(chosen));
 	return chosen;
 }
 
@@ -408,6 +427,7 @@ static int oom_kill_process(struct task_struct *p, gfp_t gfp_mask, int order,
 {
 	struct task_struct *c;
 
+#if 0
 	if (printk_ratelimit()) {
 		printk(KERN_WARNING "%s invoked oom-killer: "
 			"gfp_mask=0x%x, order=%d, oom_adj=%d\n",
@@ -422,6 +442,7 @@ static int oom_kill_process(struct task_struct *p, gfp_t gfp_mask, int order,
 		if (sysctl_oom_dump_tasks)
 			dump_tasks(mem);
 	}
+#endif
 
 	/*
 	 * If the task is already exiting, don't alarm the sysadmin or kill
